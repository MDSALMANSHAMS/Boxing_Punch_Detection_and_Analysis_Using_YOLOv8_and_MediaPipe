{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\My_Projects\\Sponsorlytix_Assignment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\My_Projects\\Sponsorlytix_Assignment\\venv3.9\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd D:\\My_Projects\\Sponsorlytix_Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame extration for video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 4900 frames to Data/images_2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yt_dlp\n",
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_path = os.path.join(output_folder, f\"frame_{frame_count:05d}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {frame_count} frames to {output_folder}\")\n",
    "\n",
    "video_path=\"Data/v2.mp4\"\n",
    "output_image_path=\"Data/images_2\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_frames(video_path, output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 12/12 [00:01<00:00,  8.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "INPUT_IMAGE_DIR = r\"D:\\My_Projects\\Sponsorlytix_Assignment\\Data\\Dataset\\test\\images\"\n",
    "INPUT_LABEL_DIR = r\"D:\\My_Projects\\Sponsorlytix_Assignment\\Data\\Dataset\\test\\labels\"\n",
    "OUTPUT_IMAGE_DIR = r\"D:\\My_Projects\\Sponsorlytix_Assignment\\yolov7\\Dataset\\test\\images\"\n",
    "OUTPUT_LABEL_DIR = r\"D:\\My_Projects\\Sponsorlytix_Assignment\\yolov7\\Dataset\\test\\labels\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(OUTPUT_IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_LABEL_DIR, exist_ok=True)\n",
    "\n",
    "# Define augmentations (Only shape-preserving)\n",
    "augmentations = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        #A.RandomRotate90(p=0.5),\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.7),\n",
    "        A.Affine(scale=(0.8, 1.2), translate_percent=(0.1, 0.2), rotate=(-30, 30), shear=(-10, 10), p=0.7),\n",
    "\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])\n",
    ")\n",
    "\n",
    "# Helper function to read annotations\n",
    "def read_yolo_annotation(label_path):\n",
    "    with open(label_path, \"r\") as file:\n",
    "        bboxes = []\n",
    "        class_labels = []\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            class_labels.append(int(parts[0]))\n",
    "            bbox = list(map(float, parts[1:]))\n",
    "            bboxes.append(bbox)\n",
    "        return bboxes, class_labels\n",
    "\n",
    "# Helper function to write annotations\n",
    "def write_yolo_annotation(output_path, bboxes, class_labels):\n",
    "    with open(output_path, \"w\") as file:\n",
    "        for cls, bbox in zip(class_labels, bboxes):\n",
    "            bbox_line = f\"{int(cls)} \" + \" \".join(map(str, bbox))\n",
    "            file.write(bbox_line + \"\\n\")\n",
    "\n",
    "# Process dataset\n",
    "for image_file in tqdm(os.listdir(INPUT_IMAGE_DIR), desc=\"Processing Images\"):\n",
    "    if image_file.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        # Load image and label\n",
    "        image_path = os.path.join(INPUT_IMAGE_DIR, image_file)\n",
    "        \n",
    "        # Handling label file variations\n",
    "        label_filename = image_file.rsplit(\".\", 1)[0]  # Remove extension\n",
    "        label_path = os.path.join(INPUT_LABEL_DIR, f\"{label_filename}.txt\")\n",
    "\n",
    "        # Try alternative label name format (e.g., frame_00243.xml.txt)\n",
    "        if not os.path.exists(label_path):\n",
    "            alternative_label_path = os.path.join(INPUT_LABEL_DIR, f\"{label_filename}.xml.txt\")\n",
    "            if os.path.exists(alternative_label_path):\n",
    "                label_path = alternative_label_path\n",
    "            else:\n",
    "                print(f\"Skipping {image_file}: No corresponding label file found.\")\n",
    "                continue\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Skipping {image_file}: Failed to load image.\")\n",
    "            continue\n",
    "        \n",
    "        img_height, img_width = image.shape[:2]\n",
    "\n",
    "        # Ensure image shape remains constant\n",
    "        if (img_width, img_height) != (1280, 720):\n",
    "            print(f\"Skipping {image_file}: Image shape changed.\")\n",
    "            continue\n",
    "\n",
    "        # Read bounding boxes\n",
    "        bboxes, class_labels = read_yolo_annotation(label_path)\n",
    "\n",
    "        # Copy original image & label to output directory\n",
    "        shutil.copy(image_path, os.path.join(OUTPUT_IMAGE_DIR, image_file))\n",
    "        shutil.copy(label_path, os.path.join(OUTPUT_LABEL_DIR, f\"{label_filename}.txt\"))\n",
    "\n",
    "        if len(bboxes) == 0:\n",
    "            continue  # Skip if no bounding boxes\n",
    "\n",
    "        # Apply augmentation\n",
    "        for i in range(5):  # Generate 5 augmented versions per image\n",
    "            augmented = augmentations(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "\n",
    "            augmented_image = augmented[\"image\"]\n",
    "            augmented_bboxes = augmented[\"bboxes\"]\n",
    "            augmented_class_labels = augmented[\"class_labels\"]\n",
    "\n",
    "            # Convert image back to BGR before saving\n",
    "            augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Save augmented image\n",
    "            aug_image_path = os.path.join(OUTPUT_IMAGE_DIR, f\"{image_file[:-4]}_aug{i}.jpg\")\n",
    "            cv2.imwrite(aug_image_path, augmented_image)\n",
    "\n",
    "            # Save augmented labels\n",
    "            aug_label_path = os.path.join(OUTPUT_LABEL_DIR, f\"{image_file[:-4]}_aug{i}.txt\")\n",
    "            write_yolo_annotation(aug_label_path, augmented_bboxes, augmented_class_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing Annotations: 100%|██████████| 72/72 [00:01<00:00, 39.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Annotation visualization completed. Check the 'visualized' folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "IMAGE_DIR = r\"D:\\My_Projects\\Sponsorlytix_Assignment\\yolov7\\Dataset\\test\\images\"\n",
    "LABEL_DIR = r\"D:\\My_Projects\\Sponsorlytix_Assignment\\yolov7\\Dataset\\test\\labels\"\n",
    "OUTPUT_DIR = r\"D:\\My_Projects\\Sponsorlytix_Assignment\\yolov7\\Dataset\\test\\visualized\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Class names (modify according to your dataset)\n",
    "CLASS_NAMES = {\n",
    "    0: \"Jab\",\n",
    "    1: \"Punching bag\",\n",
    "    2: \"Hook\",\n",
    "    3: \"Uppercut\"\n",
    "}\n",
    "\n",
    "# Colors for different classes\n",
    "COLORS = [\n",
    "    (0, 255, 0),  # Green\n",
    "    (255, 0, 0),  # Blue\n",
    "    (0, 0, 255),  # Red\n",
    "    (255, 255, 0)  # Cyan\n",
    "]\n",
    "\n",
    "# Helper function to read YOLO annotations\n",
    "def read_yolo_annotation(label_path, img_width, img_height):\n",
    "    with open(label_path, \"r\") as file:\n",
    "        bboxes = []\n",
    "        class_labels = []\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            \n",
    "            # Convert YOLO format (normalized) to pixel coordinates\n",
    "            x_min = int((x_center - width / 2) * img_width)\n",
    "            y_min = int((y_center - height / 2) * img_height)\n",
    "            x_max = int((x_center + width / 2) * img_width)\n",
    "            y_max = int((y_center + height / 2) * img_height)\n",
    "            \n",
    "            bboxes.append((x_min, y_min, x_max, y_max))\n",
    "            class_labels.append(class_id)\n",
    "    \n",
    "    return bboxes, class_labels\n",
    "\n",
    "# Loop through images\n",
    "for image_file in tqdm(os.listdir(IMAGE_DIR), desc=\"Visualizing Annotations\"):\n",
    "    if image_file.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        image_path = os.path.join(IMAGE_DIR, image_file)\n",
    "        label_path = os.path.join(LABEL_DIR, image_file.rsplit(\".\", 1)[0] + \".txt\")\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Skipping {image_file}: No corresponding label file found.\")\n",
    "            continue\n",
    "\n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Skipping {image_file}: Could not load image.\")\n",
    "            continue\n",
    "\n",
    "        img_height, img_width = image.shape[:2]\n",
    "\n",
    "        # Read bounding boxes\n",
    "        bboxes, class_labels = read_yolo_annotation(label_path, img_width, img_height)\n",
    "\n",
    "        # Draw bounding boxes on the image\n",
    "        for bbox, class_id in zip(bboxes, class_labels):\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "            color = COLORS[class_id % len(COLORS)]  # Assign color based on class\n",
    "\n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "\n",
    "            # Put class label\n",
    "            label = CLASS_NAMES.get(class_id, f\"Class {class_id}\")\n",
    "            cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Save the visualized image\n",
    "        output_path = os.path.join(OUTPUT_DIR, image_file)\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "print(\"✅ Annotation visualization completed. Check the 'visualized' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
